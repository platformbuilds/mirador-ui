```
Application Layer Investigation:
â”œâ”€â”€ ðŸ”§ Kafka Performance Analysis:
â”‚   â”œâ”€â”€ Metric Discovery:
â”‚   â”‚   â”œâ”€â”€ API Call: GET /api/v1/labels
â”‚   â”‚   â”œâ”€â”€ Kafka Metrics Filter:
â”‚   â”‚   â”‚   â”œâ”€â”€ kafka_consumer_lag_total
â”‚   â”‚   â”‚   â”œâ”€â”€ kafka_broker_messages_in_rate
â”‚   â”‚   â”‚   â”œâ”€â”€ kafka_request_handler_avg_idle_percent
â”‚   â”‚   â”‚   â””â”€â”€ kafka_network_request_rate
â”‚   â”œâ”€â”€ Consumer Lag Analysis:
â”‚   â”‚   â”œâ”€â”€ API Call: GET /api/v1/query_range
â”‚   â”‚   â”œâ”€â”€ PromQL Query: "kafka_consumer_lag_total{topic='payment-transactions'}"
â”‚   â”‚   â”œâ”€â”€ Lag Timeline Correlation:
â”‚   â”‚   â”‚   â”œâ”€â”€ T-180s: Consumer lag normal at <100 messages
â”‚   â”‚   â”‚   â”œâ”€â”€ T-120s: Lag increases to 5,000 messages
â”‚   â”‚   â”‚   â”œâ”€â”€ T-90s: Lag spikes to 25,000 messages
â”‚   â”‚   â”‚   â”œâ”€â”€ T-60s: Lag critical at 50,000 messages
â”‚   â”‚   â”‚   â””â”€â”€ Correlation: Lag buildup 60s before transaction failures
â”‚   â”‚   â””â”€â”€ Impact Analysis:
â”‚   â”‚       â”œâ”€â”€ Transaction processing delays
â”‚   â”‚       â”œâ”€â”€ Bank-specific topic lag correlation
â”‚   â”‚       â”œâ”€â”€ Consumer group rebalancing issues
â”‚   â”‚       â””â”€â”€ Message processing bottlenecks
â”œâ”€â”€ ðŸ’¾ Cassandra Performance Analysis:
â”‚   â”œâ”€â”€ Database Metrics Discovery:
â”‚   â”‚   â”œâ”€â”€ API Call: GET /api/v1/labels
â”‚   â”‚   â”œâ”€â”€ Cassandra Metrics:
â”‚   â”‚   â”‚   â”œâ”€â”€ cassandra_read_latency_seconds
â”‚   â”‚   â”‚   â”œâ”€â”€ cassandra_write_latency_seconds
â”‚   â”‚   â”‚   â”œâ”€â”€ cassandra_pending_compactions
â”‚   â”‚   â”‚   â””â”€â”€ cassandra_active_connections
â”‚   â”œâ”€â”€ Read Latency Correlation:
â”‚   â”‚   â”œâ”€â”€ API Call: GET /api/v1/query_range
â”‚   â”‚   â”œâ”€â”€ PromQL Query: "cassandra_read_latency_seconds{quantile='0.95'}"
â”‚   â”‚   â”œâ”€â”€ Latency Timeline:
â”‚   â”‚   â”‚   â”œâ”€â”€ T-150s: Read latency normal at 5ms P95
â”‚   â”‚   â”‚   â”œâ”€â”€ T-120s: Latency increases to 25ms P95
â”‚   â”‚   â”‚   â”œâ”€â”€ T-90s: Latency spikes to 100ms P95
â”‚   â”‚   â”‚   â”œâ”€â”€ T-60s: Latency critical at 200ms P95
â”‚   â”‚   â”‚   â””â”€â”€ Correlation: DB latency spike correlates with transaction timeouts
â”‚   â”‚   â””â”€â”€ Database Impact Analysis:
â”‚   â”‚       â”œâ”€â”€ Connection pool exhaustion
â”‚   â”‚       â”œâ”€â”€ Query timeout increases
â”‚   â”‚       â”œâ”€â”€ Compaction operation interference
â”‚   â”‚       â””â”€â”€ Replication lag impact
â”œâ”€â”€ âš¡ Redis Cache Performance Analysis:
â”‚   â”œâ”€â”€ Cache Metrics Discovery:
â”‚   â”‚   â”œâ”€â”€ API Call: GET /api/v1/labels
â”‚   â”‚   â”œâ”€â”€ Redis Metrics:
â”‚   â”‚   â”‚   â”œâ”€â”€ redis_connected_clients
â”‚   â”‚   â”‚   â”œâ”€â”€ redis_memory_used_bytes
â”‚   â”‚   â”‚   â”œâ”€â”€ redis_keyspace_hits_total
â”‚   â”‚   â”‚   â””â”€â”€ redis_commands_processed_total
â”‚   â”œâ”€â”€ Cache Hit Rate Analysis:
â”‚   â”‚   â”œâ”€â”€ API Call: GET /api/v1/query_range
â”‚   â”‚   â”œâ”€â”€ PromQL Query: "rate(redis_keyspace_hits_total[5m]) / (rate(redis_keyspace_hits_total[5m]) + rate(redis_keyspace_misses_total[5m])) * 100"
â”‚   â”‚   â”œâ”€â”€ Hit Rate Timeline:
â”‚   â”‚   â”‚   â”œâ”€â”€ T-180s: Hit rate normal at 95%
â”‚   â”‚   â”‚   â”œâ”€â”€ T-120s: Hit rate drops to 85%
â”‚   â”‚   â”‚   â”œâ”€â”€ T-90s: Hit rate drops to 70%
â”‚   â”‚   â”‚   â”œâ”€â”€ T-60s: Hit rate critical at 65%
â”‚   â”‚   â”‚   â””â”€â”€ Correlation: Cache miss spike forces database load
â”‚   â”‚   â””â”€â”€ Cache Impact Analysis:
â”‚   â”‚       â”œâ”€â”€ Memory eviction patterns
â”‚   â”‚       â”œâ”€â”€ Connection pool saturation
â”‚   â”‚       â”œâ”€â”€ Key expiration policy effects
â”‚   â”‚       â””â”€â”€ Database load increase correlation
â””â”€â”€ ðŸ“Š JVM Performance Analysis:
    â”œâ”€â”€ JVM Metrics Discovery:
    â”‚   â”œâ”€â”€ API Call: GET /api/v1/labels
    â”‚   â”œâ”€â”€ JVM Metrics:
    â”‚   â”‚   â”œâ”€â”€ jvm_memory_used_bytes
    â”‚   â”‚   â”œâ”€â”€ jvm_gc_collection_seconds
    â”‚   â”‚   â”œâ”€â”€ jvm_threads_current
    â”‚   â”‚   â””â”€â”€ jvm_classes_loaded
    â”œâ”€â”€ Garbage Collection Impact:
    â”‚   â”œâ”€â”€ API Call: GET /api/v1/query_range
    â”‚   â”œâ”€â”€ PromQL Query: "rate(jvm_gc_collection_seconds_total[5m])"
    â”‚   â”œâ”€â”€ GC Timeline Correlation:
    â”‚   â”‚   â”œâ”€â”€ T-150s: GC normal at 100ms/minute
    â”‚   â”‚   â”œâ”€â”€ T-120s: GC increases to 500ms/minute
    â”‚   â”‚   â”œâ”€â”€ T-90s: GC spikes to 2000ms/minute
    â”‚   â”‚   â”œâ”€â”€ T-60s: GC critical at 5000ms/minute (5s pauses)
    â”‚   â”‚   â””â”€â”€ Correlation: GC pause spikes correlate with transaction timeouts
    â””â”€â”€ Thread Pool Analysis:
        â”œâ”€â”€ Thread pool utilization metrics
        â”œâ”€â”€ Queue depth measurements
        â”œâ”€â”€ Thread starvation detection
        â””â”€â”€ Request rejection correlation
```
